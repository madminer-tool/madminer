
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>madminer.ml module &#8212; MadMiner 0.1.1 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="madminer.morphing module" href="madminer.morphing.html" />
    <link rel="prev" title="madminer.fisherinformation module" href="madminer.fisherinformation.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="module-madminer.ml">
<span id="madminer-ml-module"></span><h1>madminer.ml module<a class="headerlink" href="#module-madminer.ml" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="madminer.ml.EnsembleForge">
<em class="property">class </em><code class="descclassname">madminer.ml.</code><code class="descname">EnsembleForge</code><span class="sig-paren">(</span><em>estimators=None</em>, <em>debug=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/madminer/ml.html#EnsembleForge"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#madminer.ml.EnsembleForge" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Ensemble methods for likelihood ratio and score information.</p>
<p>Generally, EnsembleForge instances can be used very similarly to MLForge instances:</p>
<ul class="simple">
<li>The initialization of EnsembleForge takes a list of (trained or untrained) MLForge instances.</li>
<li>The methods <cite>EnsembleForge.train_one()</cite> and <cite>EnsembleForge.train_all()</cite> train the estimators (this can also be
done outside of EnsembleForge).</li>
<li><cite>EnsembleForge.calculate_expectation()</cite> can be used to calculate the expectation of the estimation likelihood
ratio or the expected estimated score over a validation sample. Ideally (and assuming the correct sampling),
these expectation values should be close to zero. Deviations from zero therefore point out that the estimator
is probably inaccurate.</li>
<li><cite>EnsembleForge.evaluate()</cite> and <cite>EnsembleForge.calculate_fisher_information()</cite> can then be used to calculate
ensemble predictions. The user has the option to treat all estimators equally (‘committee method’) or to give those
with expected score / ratio close to zero a higher weight.</li>
<li><cite>EnsembleForge.save()</cite> and <cite>EnsembleForge.load()</cite> can store all estimators in one folder.</li>
</ul>
<p>The individual estimators in the ensemble can be trained with different methods, but they have to be of the same
type: either all estimators are single-parameterized likelihood ratio estimators, or all estimators are
doubly-parameterized likelihood estimators, or all estimators are local score regressors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>estimators</strong> <span class="classifier-delimiter">:</span> <span class="classifier">None or int or list of (MLForge or str), optional</span></dt>
<dd><p class="first last">If int, sets the number of estimators that will be created as new MLForge instances. If list, sets
the estimators directly, either from MLForge instances or filenames (that are then loaded with
<cite>MLForge.load()</cite>). If None, the ensemble is initialized without estimators. Note that the estimators have
to be consistent: either all of them are trained with a local score method (‘sally’ or ‘sallino’); or all of
them are trained with a single-parameterized method (‘carl’, ‘rolr’, ‘rascal’, ‘scandal’, ‘alice’, or ‘alices’);
or all of them are trained with a doubly parameterized method (‘carl2’, ‘rolr2’, ‘rascal2’, ‘alice2’, or
‘alices2’). Mixing estimators of different types within one of these three categories is supported, but mixing
estimators from different categories is not and will raise a RuntimeException. Default value: None.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Attributes:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>estimators</strong> <span class="classifier-delimiter">:</span> <span class="classifier">list of MLForge</span></dt>
<dd><p class="first last">The estimators in the form of MLForge instances.</p>
</dd>
<dt><strong>debug</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">If True, additional detailed debugging output is printed. Default value: False.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#madminer.ml.EnsembleForge.add_estimator" title="madminer.ml.EnsembleForge.add_estimator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_estimator</span></code></a>(estimator)</td>
<td>Adds an estimator to the ensemble.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#madminer.ml.EnsembleForge.calculate_expectation" title="madminer.ml.EnsembleForge.calculate_expectation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">calculate_expectation</span></code></a>(x_filename[,&nbsp;…])</td>
<td>Calculates the expectation of the estimation likelihood ratio or the expected estimated score over a validation sample.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#madminer.ml.EnsembleForge.calculate_fisher_information" title="madminer.ml.EnsembleForge.calculate_fisher_information"><code class="xref py py-obj docutils literal notranslate"><span class="pre">calculate_fisher_information</span></code></a>(x[,&nbsp;…])</td>
<td>Calculates the expected Fisher information matrices for each estimator, and then returns the ensemble mean and variance.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#madminer.ml.EnsembleForge.evaluate" title="madminer.ml.EnsembleForge.evaluate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate</span></code></a>(x_filename[,&nbsp;theta0_filename,&nbsp;…])</td>
<td>Evaluates the estimators of the likelihood ratio (or, if method is ‘sally’ or ‘sallino’, the score), and calculates the ensemble mean or variance.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#madminer.ml.EnsembleForge.load" title="madminer.ml.EnsembleForge.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(folder)</td>
<td>Loads the estimator ensemble from a folder.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#madminer.ml.EnsembleForge.save" title="madminer.ml.EnsembleForge.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(folder)</td>
<td>Saves the estimator ensemble to a folder.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#madminer.ml.EnsembleForge.train_all" title="madminer.ml.EnsembleForge.train_all"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_all</span></code></a>(**kwargs)</td>
<td>Trains all estimators.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#madminer.ml.EnsembleForge.train_one" title="madminer.ml.EnsembleForge.train_one"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_one</span></code></a>(i,&nbsp;**kwargs)</td>
<td>Trains an individual estimator.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="madminer.ml.EnsembleForge.add_estimator">
<code class="descname">add_estimator</code><span class="sig-paren">(</span><em>estimator</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/madminer/ml.html#EnsembleForge.add_estimator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#madminer.ml.EnsembleForge.add_estimator" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds an estimator to the ensemble.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>estimator</strong> <span class="classifier-delimiter">:</span> <span class="classifier">MLForge or str</span></dt>
<dd><p class="first last">The estimator, either as MLForge instance or filename (which is then loaded with <cite>MLForge.load()</cite>).</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>None</strong></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="madminer.ml.EnsembleForge.calculate_expectation">
<code class="descname">calculate_expectation</code><span class="sig-paren">(</span><em>x_filename</em>, <em>theta0_filename=None</em>, <em>theta1_filename=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/madminer/ml.html#EnsembleForge.calculate_expectation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#madminer.ml.EnsembleForge.calculate_expectation" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the expectation of the estimation likelihood ratio or the expected estimated score over a validation
sample. Ideally (and assuming the correct sampling), these expectation values should be close to zero.
Deviations from zero therefore point out that the estimator is probably inaccurate.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>x_filename</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str</span></dt>
<dd><p class="first last">Path to an unweighted sample of observations, as saved by the <cite>madminer.sampling.SampleAugmenter</cite> functions.</p>
</dd>
<dt><strong>theta0_filename</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str or None, optional</span></dt>
<dd><p class="first last">Path to an unweighted sample of numerator parameters, as saved by the <cite>madminer.sampling.SampleAugmenter</cite>
functions. Required if the estimators were trained with the ‘alice’, ‘alice2’, ‘alices’, ‘alices2’, ‘carl’,
‘carl2’, ‘nde’, ‘rascal’, ‘rascal2’, ‘rolr’, ‘rolr2’, or ‘scandal’ method. Default value: None.</p>
</dd>
<dt><strong>theta1_filename</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str or None, optional</span></dt>
<dd><p class="first last">Path to an unweighted sample of denominator parameters, as saved by the <cite>madminer.sampling.SampleAugmenter</cite>
functions. Required if the estimators were trained with the ‘alice2’, ‘alices2’, ‘carl2’, ‘rascal2’, or
‘rolr2’ method. Default value: None.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>expectations</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Expected score (if the estimators were trained with the ‘sally’ or ‘sallino’ methods) or likelihood ratio
(otherwise).</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="madminer.ml.EnsembleForge.calculate_fisher_information">
<code class="descname">calculate_fisher_information</code><span class="sig-paren">(</span><em>x</em>, <em>obs_weights=None</em>, <em>n_events=1</em>, <em>uncertainty='ensemble'</em>, <em>vote_expectation_weight=None</em>, <em>return_individual_predictions=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/madminer/ml.html#EnsembleForge.calculate_fisher_information"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#madminer.ml.EnsembleForge.calculate_fisher_information" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the expected Fisher information matrices for each estimator, and then returns the ensemble mean and
variance.</p>
<p>The user has the option to treat all estimators equally (‘committee method’) or to give those with expected
score / ratio close to zero (as calculated by <cite>calculate_expectation()</cite>) a higher weight. In the latter case,
the ensemble mean <cite>I</cite> is calculated as <cite>I  =  sum_i w_i I_i</cite> with weights
<cite>w_i  =  exp(-vote_expectation_weight |E[t_i]|) / sum_j exp(-vote_expectation_weight |E[t_k]|)</cite>. Here <cite>I_i</cite>
are the individual estimators and <cite>E[t_i]</cite> is the expectation value calculated by <cite>calculate_expectation()</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>x</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str</span></dt>
<dd><p class="first last">Sample of observations, or path to numpy file with observations, as saved by the
<cite>madminer.sampling.SampleAugmenter</cite> functions. Note that this sample has to be sampled from the reference
parameter where the score is estimated with the SALLY / SALLINO estimator!</p>
</dd>
<dt><strong>obs_weights</strong> <span class="classifier-delimiter">:</span> <span class="classifier">None or ndarray, optional</span></dt>
<dd><p class="first last">Weights for the observations. If None, all events are taken to have equal weight. Default value: None.</p>
</dd>
<dt><strong>n_events</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Expected number of events for which the kinematic Fisher information should be calculated. Default value: 1.</p>
</dd>
<dt><strong>uncertainty</strong> <span class="classifier-delimiter">:</span> <span class="classifier">{“ensemble”, “expectation”, “sum”}, optional</span></dt>
<dd><p class="first last">How the covariance matrix of the Fisher information estimate is calculate. With “ensemble”, the ensemble
covariance is used. With “expectation”, the expectation of the score is used as a measure of the uncertainty
of the score estimator, and this uncertainty is propagated through to the covariance matrix. With “sum”,
both terms are summed. Default value: “ensemble”.</p>
</dd>
<dt><strong>vote_expectation_weight</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float or list of float or None, optional</span></dt>
<dd><p class="first last">Factor that determines how much more weight is given to those estimators with small expectation value (as
calculated by <cite>calculate_expectation()</cite>). If a list is given, results are returned for each element in the
list. If None, or if <cite>calculate_expectation()</cite> has not been called, all estimators are treated equal.
Default value: None.</p>
</dd>
<dt><strong>return_individual_predictions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">Whether the individual estimator predictions are returned. Default value: False.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>mean_prediction</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray or list of ndarray</span></dt>
<dd><p class="first last">The (weighted) ensemble mean of the estimators. If the estimators were trained with <cite>method=’sally’</cite> or
<cite>method=’sallino’</cite>, this is an array of the estimator for <cite>t(x_i | theta_ref)</cite> for all events <cite>i</cite>.
Otherwise, the estimated likelihood ratio (if test_all_combinations is True, the result has shape
<cite>(n_thetas, n_x)</cite>, otherwise, it has shape <cite>(n_samples,)</cite>). If more then one value vote_expectation_weight
is given, this is a list with results for all entries in vote_expectation_weight.</p>
</dd>
<dt><strong>covariance</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray or list of ndarray</span></dt>
<dd><p class="first last">The covariance matrix of the Fisher information estimate. Its definition depends on the value of
uncertainty; by default, the covariance is defined as the ensemble covariance. This object
has four indices, <cite>cov_(ij)(i’j’)</cite>, ordered as i j i’ j’. It has shape
<cite>(n_parameters, n_parameters, n_parameters, n_parameters)</cite>. If more then one value vote_expectation_weight
is given, this is a list with results for all entries in vote_expectation_weight.</p>
</dd>
<dt><strong>weights</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray or list of ndarray</span></dt>
<dd><p class="first last">Only returned if return_individual_predictions is True. The estimator weights <cite>w_i</cite>. If more then one value
vote_expectation_weight is given, this is a list with results for all entries in vote_expectation_weight.</p>
</dd>
<dt><strong>individual_predictions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Only returned if return_individual_predictions is True. The individual estimator predictions.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="madminer.ml.EnsembleForge.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>x_filename</em>, <em>theta0_filename=None</em>, <em>theta1_filename=None</em>, <em>test_all_combinations=True</em>, <em>vote_expectation_weight=None</em>, <em>calculate_covariance=False</em>, <em>return_individual_predictions=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/madminer/ml.html#EnsembleForge.evaluate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#madminer.ml.EnsembleForge.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the estimators of the likelihood ratio (or, if method is ‘sally’ or ‘sallino’, the score), and
calculates the ensemble mean or variance.</p>
<p>The user has the option to treat all estimators equally (‘committee method’) or to give those with expected
score / ratio close to zero (as calculated by <cite>calculate_expectation()</cite>) a higher weight. In the latter case,
the ensemble mean <cite>f(x)</cite> is calculated as <cite>f(x)  =  sum_i w_i f_i(x)</cite> with weights
<cite>w_i  =  exp(-vote_expectation_weight |E[f_i]|) / sum_j exp(-vote_expectation_weight |E[f_j]|)</cite>. Here <cite>f_i(x)</cite>
are the individual estimators and <cite>E[f_i]</cite> is the expectation value calculated by <cite>calculate_expectation()</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>x_filename</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str</span></dt>
<dd><p class="first last">Path to an unweighted sample of observations, as saved by the <cite>madminer.sampling.SampleAugmenter</cite> functions.</p>
</dd>
<dt><strong>theta0_filename</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str or None, optional</span></dt>
<dd><p class="first last">Path to an unweighted sample of numerator parameters, as saved by the <cite>madminer.sampling.SampleAugmenter</cite>
functions. Required if the estimator was trained with the ‘alice’, ‘alice2’, ‘alices’, ‘alices2’, ‘carl’,
‘carl2’, ‘nde’, ‘rascal’, ‘rascal2’, ‘rolr’, ‘rolr2’, or ‘scandal’ method. Default value: None.</p>
</dd>
<dt><strong>theta1_filename</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str or None, optional</span></dt>
<dd><p class="first last">Path to an unweighted sample of denominator parameters, as saved by the <cite>madminer.sampling.SampleAugmenter</cite>
functions. Required if the estimator was trained with the ‘alice2’, ‘alices2’, ‘carl2’, ‘rascal2’, or
‘rolr2’ method. Default value: None.</p>
</dd>
<dt><strong>test_all_combinations</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">If method is not ‘sally’ and not ‘sallino’: If False, the number of samples in the observable and theta
files has to match, and the likelihood ratio is evaluated only for the combinations
<cite>r(x_i | theta0_i, theta1_i)</cite>. If True, <cite>r(x_i | theta0_j, theta1_j)</cite> for all pairwise combinations <cite>i, j</cite>
are evaluated. Default value: True.</p>
</dd>
<dt><strong>vote_expectation_weight</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float or list of float or None, optional</span></dt>
<dd><p class="first last">Factor that determines how much more weight is given to those estimators with small expectation value (as
calculated by <cite>calculate_expectation()</cite>). If a list is given, results are returned for each element in the
list. If None, or if <cite>calculate_expectation()</cite> has not been called, all estimators are treated equal.
Default value: None.</p>
</dd>
<dt><strong>calculate_covariance</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">Whether the covariance matrix is calculated. Default value: False.</p>
</dd>
<dt><strong>return_individual_predictions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">Whether the individual estimator predictions are returned. Default value: False.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>mean_prediction</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray or list of ndarray</span></dt>
<dd><p class="first last">The (weighted) ensemble mean of the estimators. If the estimators were trained with <cite>method=’sally’</cite> or
<cite>method=’sallino’</cite>, this is an array of the estimator for <cite>t(x_i | theta_ref)</cite> for all events <cite>i</cite>.
Otherwise, the estimated likelihood ratio (if test_all_combinations is True, the result has shape
<cite>(n_thetas, n_x)</cite>, otherwise, it has shape <cite>(n_samples,)</cite>). If more then one value vote_expectation_weight
is given, this is a list with results for all entries in vote_expectation_weight.</p>
</dd>
<dt><strong>covariance</strong> <span class="classifier-delimiter">:</span> <span class="classifier">None or ndarray or list of ndarray</span></dt>
<dd><p class="first last">The covariance matrix of the (flattened) predictions, defined as the ensemble covariance. If more then one
value vote_expectation_weight is given, this is a list with results
for all entries in vote_expectation_weight. If calculate_covariance is False, None is returned.</p>
</dd>
<dt><strong>weights</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray or list of ndarray</span></dt>
<dd><p class="first last">Only returned if return_individual_predictions is True. The estimator weights <cite>w_i</cite>. If more then one value
vote_expectation_weight is given, this is a list with results for all entries in vote_expectation_weight.</p>
</dd>
<dt><strong>individual_predictions</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Only returned if return_individual_predictions is True. The individual estimator predictions.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="madminer.ml.EnsembleForge.load">
<code class="descname">load</code><span class="sig-paren">(</span><em>folder</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/madminer/ml.html#EnsembleForge.load"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#madminer.ml.EnsembleForge.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads the estimator ensemble from a folder.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>folder</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str</span></dt>
<dd><p class="first last">Path to the folder.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>None</strong></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="madminer.ml.EnsembleForge.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>folder</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/madminer/ml.html#EnsembleForge.save"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#madminer.ml.EnsembleForge.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves the estimator ensemble to a folder.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>folder</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str</span></dt>
<dd><p class="first last">Path to the folder.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>None</strong></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="madminer.ml.EnsembleForge.train_all">
<code class="descname">train_all</code><span class="sig-paren">(</span><em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/madminer/ml.html#EnsembleForge.train_all"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#madminer.ml.EnsembleForge.train_all" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains all estimators. See <cite>MLForge.train()</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>kwargs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">Parameters for <cite>MLForge.train()</cite>. If a value in this dict is a list, it has to have length <cite>n_estimators</cite>
and contain one value of this parameter for each of the estimators. Otherwise the value is used as parameter
for the training of all the estimators.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>None</strong></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="madminer.ml.EnsembleForge.train_one">
<code class="descname">train_one</code><span class="sig-paren">(</span><em>i</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/madminer/ml.html#EnsembleForge.train_one"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#madminer.ml.EnsembleForge.train_one" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains an individual estimator. See <cite>MLForge.train()</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>i</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The index <cite>0 &lt;= i &lt; n_estimators</cite> of the estimator to be trained.</p>
</dd>
<dt><strong>kwargs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">Parameters for <cite>MLForge.train()</cite>.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>None</strong></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="madminer.ml.MLForge">
<em class="property">class </em><code class="descclassname">madminer.ml.</code><code class="descname">MLForge</code><span class="sig-paren">(</span><em>debug=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/madminer/ml.html#MLForge"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#madminer.ml.MLForge" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Estimating likelihood ratios and scores with machine learning.</p>
<p>Each instance of this class represents one neural estimator. The most important functions are:</p>
<ul class="simple">
<li><cite>MLForge.train()</cite> to train an estimator. The keyword <cite>method</cite> determines the inference technique
and whether a class instance represents a single-parameterized likelihood ratio estimator, a doubly-parameterized
likelihood ratio estimator, or a local score estimator.</li>
<li><cite>MLForge.evaluate()</cite> to evaluate the estimator.</li>
<li><cite>MLForge.save()</cite> to save the trained model to files.</li>
<li><cite>MLForge.load()</cite> to load the trained model from files.</li>
</ul>
<p>Please see the tutorial for a detailed walk-through.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>debug</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">If True, additional detailed debugging output is printed. Default value: False.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#madminer.ml.MLForge.calculate_fisher_information" title="madminer.ml.MLForge.calculate_fisher_information"><code class="xref py py-obj docutils literal notranslate"><span class="pre">calculate_fisher_information</span></code></a>(x[,&nbsp;weights,&nbsp;…])</td>
<td>Calculates the expected Fisher information matrix based on the kinematic information in a given number of events.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#madminer.ml.MLForge.evaluate" title="madminer.ml.MLForge.evaluate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate</span></code></a>(x_filename[,&nbsp;theta0_filename,&nbsp;…])</td>
<td>Evaluates a trained estimator of the likelihood ratio (or, if method is ‘sally’ or ‘sallino’, the score).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#madminer.ml.MLForge.load" title="madminer.ml.MLForge.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(filename)</td>
<td>Loads a trained model from files.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#madminer.ml.MLForge.save" title="madminer.ml.MLForge.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(filename)</td>
<td>Saves the trained model to four files: a JSON file with the settings, a pickled pyTorch state dict file, and numpy files for the mean and variance of the inputs (used for input scaling).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#madminer.ml.MLForge.train" title="madminer.ml.MLForge.train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train</span></code></a>(method,&nbsp;x_filename[,&nbsp;y_filename,&nbsp;…])</td>
<td>Trains a neural network to estimate either the likelihood ratio or, if method is ‘sally’ or ‘sallino’, the score.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="madminer.ml.MLForge.calculate_fisher_information">
<code class="descname">calculate_fisher_information</code><span class="sig-paren">(</span><em>x</em>, <em>weights=None</em>, <em>n_events=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/madminer/ml.html#MLForge.calculate_fisher_information"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#madminer.ml.MLForge.calculate_fisher_information" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the expected Fisher information matrix based on the kinematic information in a given number of
events. Currently only supported for estimators trained with <cite>method=’sally’</cite> or <cite>method=’sallino’</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>x</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str or ndarray</span></dt>
<dd><p class="first last">Sample of observations, or path to numpy file with observations, as saved by the
<cite>madminer.sampling.SampleAugmenter</cite> functions. Note that this sample has to be sampled from the reference
parameter where the score is estimated with the SALLY / SALLINO estimator!</p>
</dd>
<dt><strong>weights</strong> <span class="classifier-delimiter">:</span> <span class="classifier">None or ndarray, optional</span></dt>
<dd><p class="first last">Weights for the observations. If None, all events are taken to have equal weight. Default value: None.</p>
</dd>
<dt><strong>n_events</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Expected number of events for which the kinematic Fisher information should be calculated. Default value: 1.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>fisher_information</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Expected kinematic Fisher information matrix with shape <cite>(n_parameters, n_parameters)</cite>.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="madminer.ml.MLForge.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>x_filename</em>, <em>theta0_filename=None</em>, <em>theta1_filename=None</em>, <em>test_all_combinations=True</em>, <em>evaluate_score=False</em>, <em>return_grad_x=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/madminer/ml.html#MLForge.evaluate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#madminer.ml.MLForge.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates a trained estimator of the likelihood ratio (or, if method is ‘sally’ or ‘sallino’, the score).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>x_filename</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str</span></dt>
<dd><p class="first last">Path to an unweighted sample of observations, as saved by the <cite>madminer.sampling.SampleAugmenter</cite> functions.</p>
</dd>
<dt><strong>theta0_filename</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str or None, optional</span></dt>
<dd><p class="first last">Path to an unweighted sample of numerator parameters, as saved by the <cite>madminer.sampling.SampleAugmenter</cite>
functions. Required if the estimator was trained with the ‘alice’, ‘alice2’, ‘alices’, ‘alices2’, ‘carl’,
‘carl2’, ‘nde’, ‘rascal’, ‘rascal2’, ‘rolr’, ‘rolr2’, or ‘scandal’ method. Default value: None.</p>
</dd>
<dt><strong>theta1_filename</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str or None, optional</span></dt>
<dd><p class="first last">Path to an unweighted sample of denominator parameters, as saved by the <cite>madminer.sampling.SampleAugmenter</cite>
functions. Required if the estimator was trained with the ‘alice2’, ‘alices2’, ‘carl2’, ‘rascal2’, or
‘rolr2’ method. Default value: None.</p>
</dd>
<dt><strong>test_all_combinations</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">If method is not ‘sally’ and not ‘sallino’: If False, the number of samples in the observable and theta
files has to match, and the likelihood ratio is evaluated only for the combinations
<cite>r(x_i | theta0_i, theta1_i)</cite>. If True, <cite>r(x_i | theta0_j, theta1_j)</cite> for all pairwise combinations <cite>i, j</cite>
are evaluated. Default value: True.</p>
</dd>
<dt><strong>evaluate_score</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">If method is not ‘sally’ and not ‘sallino’, this sets whether in addition to the likelihood ratio the score
is evaluated. Default value: False.</p>
</dd>
<dt><strong>return_grad_x</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">If True, <cite>grad_x log r(x)</cite> or <cite>grad_x t(x)</cite> (for ‘sally’ or ‘sallino’ estimators) are returned in addition
to the other outputs. Default value: False.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>sally_estimated_score</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Only returned if the network was trained with <cite>method=’sally’</cite> or <cite>method=’sallino’</cite>. In this case, an
array of the estimator for <cite>t(x_i | theta_ref)</cite> is returned for all events <cite>i</cite>.</p>
</dd>
<dt><strong>log_likelihood_ratio</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Only returned if the network was trained with neither <cite>method=’sally’</cite> nor <cite>method=’sallino’</cite>. The estimated
likelihood ratio. If test_all_combinations is True, the result has shape <cite>(n_thetas, n_x)</cite>. Otherwise, it
has shape <cite>(n_samples,)</cite>.</p>
</dd>
<dt><strong>score_theta0</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray or None</span></dt>
<dd><p class="first last">Only returned if the network was trained with neither <cite>method=’sally’</cite> nor <cite>method=’sallino’</cite>. None if
evaluate_score is False. Otherwise the derived estimated score at <cite>theta0</cite>. If test_all_combinations is
True, the result has shape <cite>(n_thetas, n_x, n_parameters)</cite>. Otherwise, it has shape
<cite>(n_samples, n_parameters)</cite>.</p>
</dd>
<dt><strong>score_theta1</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray or None</span></dt>
<dd><p class="first last">Only returned if the network was trained with neither <cite>method=’sally’</cite> nor <cite>method=’sallino’</cite>. None if
evaluate_score is False, or the network was trained with any method other than ‘alice2’, ‘alices2’, ‘carl2’,
‘rascal2’, or ‘rolr2’. Otherwise the derived estimated score at <cite>theta1</cite>. If test_all_combinations is
True, the result has shape <cite>(n_thetas, n_x, n_parameters)</cite>. Otherwise, it has shape
<cite>(n_samples, n_parameters)</cite>.</p>
</dd>
<dt><strong>grad_x</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span></dt>
<dd><p class="first last">Only returned if return_grad_x is True.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="madminer.ml.MLForge.load">
<code class="descname">load</code><span class="sig-paren">(</span><em>filename</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/madminer/ml.html#MLForge.load"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#madminer.ml.MLForge.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads a trained model from files.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>filename</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str</span></dt>
<dd><p class="first last">Path to the files. ‘_settings.json’ and ‘_state_dict.pl’ will be added.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>None</strong></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="madminer.ml.MLForge.save">
<code class="descname">save</code><span class="sig-paren">(</span><em>filename</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/madminer/ml.html#MLForge.save"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#madminer.ml.MLForge.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves the trained model to four files: a JSON file with the settings, a pickled pyTorch state dict
file, and numpy files for the mean and variance of the inputs (used for input scaling).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>filename</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str</span></dt>
<dd><p class="first last">Path to the files. ‘_settings.json’ and ‘_state_dict.pl’ will be added.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>None</strong></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="madminer.ml.MLForge.train">
<code class="descname">train</code><span class="sig-paren">(</span><em>method</em>, <em>x_filename</em>, <em>y_filename=None</em>, <em>theta0_filename=None</em>, <em>theta1_filename=None</em>, <em>r_xz_filename=None</em>, <em>t_xz0_filename=None</em>, <em>t_xz1_filename=None</em>, <em>features=None</em>, <em>nde_type='mafmog'</em>, <em>n_hidden=(100</em>, <em>100)</em>, <em>activation='tanh'</em>, <em>maf_n_mades=3</em>, <em>maf_batch_norm=False</em>, <em>maf_batch_norm_alpha=0.1</em>, <em>maf_mog_n_components=10</em>, <em>alpha=1.0</em>, <em>trainer='amsgrad'</em>, <em>n_epochs=50</em>, <em>batch_size=128</em>, <em>initial_lr=0.001</em>, <em>final_lr=0.0001</em>, <em>nesterov_momentum=None</em>, <em>validation_split=None</em>, <em>early_stopping=True</em>, <em>scale_inputs=True</em>, <em>shuffle_labels=False</em>, <em>grad_x_regularization=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/madminer/ml.html#MLForge.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#madminer.ml.MLForge.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains a neural network to estimate either the likelihood ratio or, if method is ‘sally’ or ‘sallino’, the
score.</p>
<p>The keyword method determines the structure of the estimator that an instance of this class represents:</p>
<ul class="simple">
<li>For ‘alice’, ‘alices’, ‘carl’, ‘nde’, ‘rascal’, ‘rolr’, and ‘scandal’, the neural network models
the likelihood ratio as a function of the observables <cite>x</cite> and the numerator hypothesis <cite>theta0</cite>, while
the denominator hypothesis is kept at a fixed reference value (“single-parameterized likelihood ratio
estimator”). In addition to the likelihood ratio, the estimator allows to estimate the score at <cite>theta0</cite>.</li>
<li>For ‘alice2’, ‘alices2’, ‘carl2’, ‘rascal2’, and ‘rolr2’, the neural network models
the likelihood ratio as a function of the observables <cite>x</cite>, the numerator hypothesis <cite>theta0</cite>, and the
denominator hypothesis <cite>theta1</cite> (“doubly parameterized likelihood ratio estimator”). The score at <cite>theta0</cite>
and <cite>theta1</cite> can also be evaluated.</li>
<li>For ‘sally’ and ‘sallino’, the neural networks models the score evaluated at some reference hypothesis
(“local score regression”). The likelihood ratio cannot be estimated directly from the neural network, but
can be estimated in a second step through density estimation in the estimated score space.</li>
</ul>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>method</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str</span></dt>
<dd><p class="first last">The inference method used. Allows values are ‘alice’, ‘alices’, ‘carl’, ‘nde’, ‘rascal’, ‘rolr’, and
‘scandal’ for a single-parameterized likelihood ratio estimator; ‘alice2’, ‘alices2’, ‘carl2’, ‘rascal2’,
and ‘rolr2’ for a doubly-parameterized likelihood ratio estimator; and ‘sally’ and ‘sallino’ for local
score regression.</p>
</dd>
<dt><strong>x_filename</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str</span></dt>
<dd><p class="first last">Path to an unweighted sample of observations, as saved by the <cite>madminer.sampling.SampleAugmenter</cite> functions.
Required for all inference methods.</p>
</dd>
<dt><strong>y_filename</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str or None, optional</span></dt>
<dd><p class="first last">Path to an unweighted sample of class labels, as saved by the <cite>madminer.sampling.SampleAugmenter</cite> functions.
Required for the ‘alice’, ‘alice2’, ‘alices’, ‘alices2’, ‘carl’, ‘carl2’, ‘rascal’, ‘rascal2’, ‘rolr’,
and ‘rolr2’ methods. Default value: None.</p>
</dd>
<dt><strong>theta0_filename</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str or None, optional</span></dt>
<dd><p class="first last">Path to an unweighted sample of numerator parameters, as saved by the <cite>madminer.sampling.SampleAugmenter</cite>
functions. Required for the ‘alice’, ‘alice2’, ‘alices’, ‘alices2’, ‘carl’, ‘carl2’, ‘nde’, ‘rascal’,
‘rascal2’, ‘rolr’, ‘rolr2’, and ‘scandal’ methods. Default value: None.</p>
</dd>
<dt><strong>theta1_filename</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str or None, optional</span></dt>
<dd><p class="first last">Path to an unweighted sample of denominator parameters, as saved by the <cite>madminer.sampling.SampleAugmenter</cite>
functions. Required for the ‘alice2’, ‘alices2’, ‘carl2’, ‘rascal2’, and ‘rolr2’ methods. Default value:
None.</p>
</dd>
<dt><strong>r_xz_filename</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str or None, optional</span></dt>
<dd><p class="first last">Path to an unweighted sample of joint likelihood ratios, as saved by the <cite>madminer.sampling.SampleAugmenter</cite>
functions. Required for the ‘alice’, ‘alice2’, ‘alices’, ‘alices2’, ‘rascal’, ‘rascal2’, ‘rolr’, and ‘rolr2’
methods. Default value: None.</p>
</dd>
<dt><strong>t_xz0_filename</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str or None, optional</span></dt>
<dd><p class="first last">Path to an unweighted sample of joint scores at theta0, as saved by the <cite>madminer.sampling.SampleAugmenter</cite>
functions. Required for the ‘alices’, ‘alices2’, ‘rascal’, ‘rascal2’, ‘sallino’, ‘sally’, and ‘scandal’
methods. Default value: None.</p>
</dd>
<dt><strong>t_xz1_filename</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str or None, optional</span></dt>
<dd><p class="first last">Path to an unweighted sample of joint scores at theta1, as saved by the <cite>madminer.sampling.SampleAugmenter</cite>
functions. Required for the ‘rascal2’ and ‘alices2’ methods. Default value: None.</p>
</dd>
<dt><strong>features</strong> <span class="classifier-delimiter">:</span> <span class="classifier">list of int or None, optional</span></dt>
<dd><p class="first last">Indices of observables (features) that are used as input to the neural networks. If None, all observables
are used. Default value: None.</p>
</dd>
<dt><strong>nde_type</strong> <span class="classifier-delimiter">:</span> <span class="classifier">{‘maf’, ‘mafmog’}, optional</span></dt>
<dd><p class="first last">If the method is ‘nde’ or ‘scandal’, nde_type determines the architecture used in the neural density
estimator. Currently supported are ‘maf’ for a Masked Autoregressive Flow with a Gaussian base density, or
‘mafmog’ for a Masked Autoregressive Flow with a mixture of Gaussian base densities. Default value:
‘mafmog’.</p>
</dd>
<dt><strong>n_hidden</strong> <span class="classifier-delimiter">:</span> <span class="classifier">tuple of int, optional</span></dt>
<dd><p class="first last">Units in each hidden layer in the neural networks. If method is ‘nde’ or ‘scandal’, this refers to the
setup of each individual MADE layer. Default value: (100, 100).</p>
</dd>
<dt><strong>activation</strong> <span class="classifier-delimiter">:</span> <span class="classifier">{‘tanh’, ‘sigmoid’, ‘relu’}, optional</span></dt>
<dd><p class="first last">Activation function. Default value: ‘tanh’.</p>
</dd>
<dt><strong>maf_n_mades</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">If method is ‘nde’ or ‘scandal’, this sets the number of MADE layers. Default value: 3.</p>
</dd>
<dt><strong>maf_batch_norm</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">If method is ‘nde’ or ‘scandal’, switches batch normalization layers after each MADE layer on or off.
Default: False.</p>
</dd>
<dt><strong>maf_batch_norm_alpha</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">If method is ‘nde’ or ‘scandal’ and maf_batch_norm is True, this sets the alpha parameter in the calculation
of the running average of the mean and variance. Default value: 0.1.</p>
</dd>
<dt><strong>maf_mog_n_components</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">If method is ‘nde’ or ‘scandal’ and nde_type is ‘mafmog’, this sets the number of Gaussian base components.
Default value: 10.</p>
</dd>
<dt><strong>alpha</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Hyperparameter weighting the score error in the loss function of the ‘alices’, ‘alices2’, ‘rascal’,
‘rascal2’, and ‘scandal’ methods. Default value: 1.</p>
</dd>
<dt><strong>trainer</strong> <span class="classifier-delimiter">:</span> <span class="classifier">{“adam”, “amsgrad”, “sgd”}, optional</span></dt>
<dd><p class="first last">Optimization algorithm. Default value: “amsgrad”.</p>
</dd>
<dt><strong>n_epochs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Number of epochs. Default value: 50.</p>
</dd>
<dt><strong>batch_size</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int, optional</span></dt>
<dd><p class="first last">Batch size. Default value: 128.</p>
</dd>
<dt><strong>initial_lr</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Learning rate during the first epoch, after which it exponentially decays to final_lr. Default value:
0.001.</p>
</dd>
<dt><strong>final_lr</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float, optional</span></dt>
<dd><p class="first last">Learning rate during the last epoch. Default value: 0.0001.</p>
</dd>
<dt><strong>nesterov_momentum</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float or None, optional</span></dt>
<dd><p class="first last">If trainer is “sgd”, sets the Nesterov momentum. Default value: None.</p>
</dd>
<dt><strong>validation_split</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float or None, optional</span></dt>
<dd><p class="first last">Fraction of samples used  for validation and early stopping (if early_stopping is True). If None, the entire
sample is used for training and early stopping is deactivated. Default value: None.</p>
</dd>
<dt><strong>early_stopping</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">Activates early stopping based on the validation loss (only if validation_split is not None). Default value:
True.</p>
</dd>
<dt><strong>scale_inputs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool, optional</span></dt>
<dd><p class="first last">Scale the observables to zero mean and unit variance. Default value: True.</p>
</dd>
<dt><strong>shuffle_labels</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool optional</span></dt>
<dd><p class="first last">If True, the labels (<cite>y</cite>, <cite>r_xz</cite>, <cite>t_xz</cite>) are shuffled, while the observations (<cite>x</cite>) remain in their
normal order. This serves as a closure test, in particular as cross-check against overfitting: an estimator
trained with shuffle_labels=True should predict to likelihood ratios around 1 and scores around 0.</p>
</dd>
<dt><strong>grad_x_regularization</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float or None, optional</span></dt>
<dd><p class="first last">If not None, a term of the form <cite>grad_x_regularization * |grad_x f(x)|^2</cite> is added to the loss, where <cite>f(x)</cite>
is the neural network output (the estimated log likelihood ratio or score). Default value: None.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>None</strong></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">MadMiner</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="madminer.core.html">madminer.core module</a></li>
<li class="toctree-l1"><a class="reference internal" href="madminer.delphes.html">madminer.delphes module</a></li>
<li class="toctree-l1"><a class="reference internal" href="madminer.fisherinformation.html">madminer.fisherinformation module</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">madminer.ml module</a></li>
<li class="toctree-l1"><a class="reference internal" href="madminer.morphing.html">madminer.morphing module</a></li>
<li class="toctree-l1"><a class="reference internal" href="madminer.plotting.html">madminer.plotting module</a></li>
<li class="toctree-l1"><a class="reference internal" href="madminer.sampling.html">madminer.sampling module</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="madminer.fisherinformation.html" title="previous chapter">madminer.fisherinformation module</a></li>
      <li>Next: <a href="madminer.morphing.html" title="next chapter">madminer.morphing module</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;Johann Brehmer, Felix Kling, and Kyle Cranmer 2018.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.8.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/madminer.ml.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>